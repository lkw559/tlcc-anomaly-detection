#!/usr/bin/env python3
"""
í¬ê´„ì  ì´ìƒ íƒì§€ ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸ - íš¨ìœ¨ì  ë²„ì „
- 4ê°œ ë°ì´í„°ì…‹ (WADI, SMAP, MSL, SMD-1-1)
- 2ê°œ ì—í­ (3, 5)
- 4ê°œ TLCC threshold (0.0, 0.3, 0.5, 0.7)
- ì´ 32ê°œ ì‹¤í—˜, ì•½ 2.9ì‹œê°„ ì˜ˆìƒ
"""

import os
import sys
import json
import pandas as pd
import subprocess
import time
from datetime import datetime
from pathlib import Path

# ì‹¤í—˜ ì„¤ì •
DATASETS = {
    'WADI': {},
    'SMAP': {},
    'MSL': {},
    'SMD': {'groups': ['1-1']}
}

EPOCHS = [3, 5]
TLCC_THRESHOLDS = [0.0, 0.3, 0.5, 0.7]
BATCH_SIZE = 128

# ê²°ê³¼ ì €ì¥ìš© ì»¬ëŸ¼
results_columns = [
    'timestamp', 'dataset', 'group', 'epoch', 'tlcc_threshold', 
    'use_true_tlcc', 'tlcc_binary',
    # Epsilon Extended Metrics
    'epsilon_f1', 'epsilon_precision', 'epsilon_recall',
    'epsilon_roc_auc', 'epsilon_pr_auc', 'epsilon_mcc',
    'epsilon_tp', 'epsilon_tn', 'epsilon_fp', 'epsilon_fn',
    'epsilon_threshold', 'epsilon_latency',
    # POT Extended Metrics  
    'pot_f1', 'pot_precision', 'pot_recall',
    'pot_roc_auc', 'pot_pr_auc', 'pot_mcc',
    'pot_tp', 'pot_tn', 'pot_fp', 'pot_fn',
    'pot_threshold', 'pot_latency',
    # Best Method
    'best_method', 'best_f1',
    # Experiment Info
    'output_path', 'total_time'
]

def create_experiment_dataframe():
    """ì‹¤í—˜ ê²°ê³¼ ì €ì¥ìš© ë°ì´í„°í”„ë ˆì„ ìƒì„±"""
    return pd.DataFrame(columns=results_columns)

def run_single_experiment(dataset, group, epoch, tlcc_threshold, results_df):
    """ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰"""
    print(f"\n{'='*80}")
    print(f"ğŸ§ª ì‹¤í—˜: {dataset} | Group: {group} | Epoch: {epoch} | TLCC: {tlcc_threshold}")
    print(f"{'='*80}")
    
    start_time = time.time()
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ì‹¤í—˜ ëª…ë ¹ì–´ êµ¬ì„±
    comment = f"{dataset}_comprehensive_tlcc_{tlcc_threshold}_epoch_{epoch}"
    if group:
        comment += f"_group_{group}"
    
    cmd = [
        'python', 'train_original.py',
        '--comment', comment,
        '--epoch', str(epoch),
        '--bs', str(BATCH_SIZE),
        '--dataset', dataset,
        '--tlcc_threshold', str(tlcc_threshold),
        '--use_true_tlcc', '1',
        '--tlcc_binary', '1'
    ]
    
    if dataset == 'SMD' and group:
        cmd.extend(['--group', group])
    
    try:
        print(f"ğŸš€ ì‹¤í–‰: {' '.join(cmd)}")
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=3600)
        
        if result.returncode != 0:
            print(f"âŒ ì‹¤í—˜ ì‹¤íŒ¨: {result.stderr[:500]}...")
            return results_df
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
        output_pattern = f"output/{dataset}"
        if group:
            output_pattern += f"/{group}"
        
        # ê°€ì¥ ìµœì‹  í´ë” ì°¾ê¸° (ë” ì•ˆì •ì ì¸ ë°©ë²•)
        import glob
        pattern = f"{output_pattern}/*"
        output_dirs = glob.glob(pattern)
        
        # ë””ë ‰í† ë¦¬ë§Œ í•„í„°ë§í•˜ê³  ìµœì‹ ìˆœ ì •ë ¬
        output_dirs = [d for d in output_dirs if os.path.isdir(d) and os.path.basename(d).startswith('20')]
        
        if not output_dirs:
            print(f"âŒ ê²°ê³¼ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {output_pattern}")
            return results_df
        
        # ê°€ì¥ ìµœì‹  í´ë” ì„ íƒ (ìˆ˜ì • ì‹œê°„ ê¸°ì¤€)
        latest_output = max(output_dirs, key=os.path.getmtime)
        summary_file = os.path.join(latest_output, 'summary.txt')
        
        if not os.path.exists(summary_file):
            print(f"âŒ Summary íŒŒì¼ ì—†ìŒ: {summary_file}")
            return results_df
        
        # Summary íŒŒì¼ ì½ê¸°
        with open(summary_file, 'r') as f:
            summary = json.load(f)
        
        # ê²°ê³¼ ì¶”ì¶œ
        epsilon_ext = summary.get('epsilon_extended', {})
        pot_ext = summary.get('pot_extended', {})
        
        # ìµœê³  ì„±ëŠ¥ ë°©ë²• ê²°ì •
        epsilon_f1 = epsilon_ext.get('f1', 0)
        pot_f1 = pot_ext.get('f1', 0)
        
        if epsilon_f1 >= pot_f1:
            best_method = 'epsilon'
            best_f1 = epsilon_f1
        else:
            best_method = 'pot'
            best_f1 = pot_f1
        
        # ê²°ê³¼ í–‰ ìƒì„±
        result_row = {
            'timestamp': timestamp,
            'dataset': dataset,
            'group': group if group else 'default',
            'epoch': epoch,
            'tlcc_threshold': tlcc_threshold,
            'use_true_tlcc': 1,
            'tlcc_binary': 1,
            # Epsilon Extended
            'epsilon_f1': epsilon_ext.get('f1', 0),
            'epsilon_precision': epsilon_ext.get('precision', 0),
            'epsilon_recall': epsilon_ext.get('recall', 0),
            'epsilon_roc_auc': epsilon_ext.get('roc_auc', 0),
            'epsilon_pr_auc': epsilon_ext.get('pr_auc', 0),
            'epsilon_mcc': epsilon_ext.get('mcc', 0),
            'epsilon_tp': epsilon_ext.get('TP', 0),
            'epsilon_tn': epsilon_ext.get('TN', 0),
            'epsilon_fp': epsilon_ext.get('FP', 0),
            'epsilon_fn': epsilon_ext.get('FN', 0),
            'epsilon_threshold': epsilon_ext.get('threshold', 0),
            'epsilon_latency': epsilon_ext.get('latency', 0),
            # POT Extended
            'pot_f1': pot_ext.get('f1', 0),
            'pot_precision': pot_ext.get('precision', 0),
            'pot_recall': pot_ext.get('recall', 0),
            'pot_roc_auc': pot_ext.get('roc_auc', 0),
            'pot_pr_auc': pot_ext.get('pr_auc', 0),
            'pot_mcc': pot_ext.get('mcc', 0),
            'pot_tp': pot_ext.get('TP', 0),
            'pot_tn': pot_ext.get('TN', 0),
            'pot_fp': pot_ext.get('FP', 0),
            'pot_fn': pot_ext.get('FN', 0),
            'pot_threshold': pot_ext.get('threshold', 0),
            'pot_latency': pot_ext.get('latency', 0),
            # Best Method
            'best_method': best_method,
            'best_f1': best_f1,
            # Experiment Info
            'output_path': latest_output,
            'total_time': total_time
        }
        
        # ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
        results_df = pd.concat([results_df, pd.DataFrame([result_row])], ignore_index=True)
        
        print(f"âœ… ì‹¤í—˜ ì™„ë£Œ ({total_time:.1f}ì´ˆ)")
        print(f"ğŸ“Š ìµœê³  ì„±ëŠ¥: {best_method.upper()} (F1: {best_f1:.4f})")
        
        # ì¤‘ê°„ ì €ì¥
        results_df.to_csv('comprehensive_experiment_results_temp.csv', index=False)
        
    except subprocess.TimeoutExpired:
        print(f"â° ì‹¤í—˜ íƒ€ì„ì•„ì›ƒ (1ì‹œê°„ ì´ˆê³¼)")
    except Exception as e:
        print(f"âŒ ì‹¤í—˜ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    return results_df

def run_comprehensive_experiments():
    """í¬ê´„ì  ì‹¤í—˜ ì‹¤í–‰"""
    print("ğŸ¯ í¬ê´„ì  ì´ìƒ íƒì§€ ì‹¤í—˜ ì‹œì‘")
    print(f"ğŸ“… ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    results_df = create_experiment_dataframe()
    
    total_experiments = 0
    completed_experiments = 0
    
    # ì´ ì‹¤í—˜ ìˆ˜ ê³„ì‚°
    for dataset, config in DATASETS.items():
        if dataset == 'SMD':
            total_experiments += len(config['groups']) * len(EPOCHS) * len(TLCC_THRESHOLDS)
        else:
            total_experiments += len(EPOCHS) * len(TLCC_THRESHOLDS)
    
    print(f"ğŸ“Š ì´ ì‹¤í—˜ ìˆ˜: {total_experiments}")
    
    # ê° ë°ì´í„°ì…‹ë³„ ì‹¤í—˜
    for dataset, config in DATASETS.items():
        print(f"\nğŸ”¬ {dataset} ë°ì´í„°ì…‹ ì‹¤í—˜ ì‹œì‘")
        
        if dataset == 'SMD':
            for group in config['groups']:
                for epoch in EPOCHS:
                    for tlcc_threshold in TLCC_THRESHOLDS:
                        results_df = run_single_experiment(
                            dataset, group, epoch, tlcc_threshold, results_df
                        )
                        completed_experiments += 1
                        print(f"ğŸ“ˆ ì§„í–‰ë¥ : {completed_experiments}/{total_experiments} "
                              f"({completed_experiments/total_experiments*100:.1f}%)")
        else:
            for epoch in EPOCHS:
                for tlcc_threshold in TLCC_THRESHOLDS:
                    results_df = run_single_experiment(
                        dataset, None, epoch, tlcc_threshold, results_df
                    )
                    completed_experiments += 1
                    print(f"ğŸ“ˆ ì§„í–‰ë¥ : {completed_experiments}/{total_experiments} "
                          f"({completed_experiments/total_experiments*100:.1f}%)")
    
    # ìµœì¢… ê²°ê³¼ ì €ì¥
    final_filename = f"comprehensive_experiment_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    results_df.to_csv(final_filename, index=False)
    
    print(f"\nğŸ‰ ëª¨ë“  ì‹¤í—˜ ì™„ë£Œ!")
    print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {final_filename}")
    print(f"ğŸ“Š ì´ ì™„ë£Œëœ ì‹¤í—˜: {completed_experiments}/{total_experiments}")
    
    # ê°„ë‹¨í•œ ìš”ì•½ í†µê³„
    if len(results_df) > 0:
        print(f"\nğŸ“‹ ì‹¤í—˜ ìš”ì•½:")
        for dataset in results_df['dataset'].unique():
            count = len(results_df[results_df['dataset'] == dataset])
            avg_f1 = results_df[results_df['dataset'] == dataset]['best_f1'].mean()
            print(f"   {dataset}: {count}ê°œ ì‹¤í—˜, í‰ê·  F1: {avg_f1:.4f}")
    
    return results_df

if __name__ == "__main__":
    # ì‘ì—… ë””ë ‰í† ë¦¬ í™•ì¸
    os.chdir('/home/timeseries/[filtered_data]S53CCF/Smartfactory/experiment_WaDi')
    
    # ì‹¤í—˜ ì‹¤í–‰
    results = run_comprehensive_experiments()
