#!/usr/bin/env python3
"""
í¬ê´„ì  ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™” ìŠ¤í¬ë¦½íŠ¸
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

def load_experiment_results(filename):
    """ì‹¤í—˜ ê²°ê³¼ CSV íŒŒì¼ ë¡œë“œ"""
    try:
        df = pd.read_csv(filename)
        print(f"âœ… ì‹¤í—˜ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ì‹¤í—˜")
        return df
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filename}")
        return None

def analyze_by_dataset(df):
    """ë°ì´í„°ì…‹ë³„ ì„±ëŠ¥ ë¶„ì„"""
    print("\n" + "="*60)
    print("ğŸ“Š ë°ì´í„°ì…‹ë³„ ì„±ëŠ¥ ë¶„ì„")
    print("="*60)
    
    metrics = ['best_f1', 'epsilon_roc_auc', 'epsilon_pr_auc', 'epsilon_mcc', 
               'pot_roc_auc', 'pot_pr_auc', 'pot_mcc']
    
    for dataset in df['dataset'].unique():
        dataset_data = df[df['dataset'] == dataset]
        print(f"\nğŸ”¬ {dataset} ë°ì´í„°ì…‹ ({len(dataset_data)}ê°œ ì‹¤í—˜)")
        print("-" * 40)
        
        for metric in metrics:
            if metric in dataset_data.columns:
                mean_val = dataset_data[metric].mean()
                std_val = dataset_data[metric].std()
                max_val = dataset_data[metric].max()
                print(f"   {metric:15}: {mean_val:.4f} Â± {std_val:.4f} (max: {max_val:.4f})")

def analyze_by_tlcc_threshold(df):
    """TLCC thresholdë³„ ì„±ëŠ¥ ë¶„ì„"""
    print("\n" + "="*60)
    print("ğŸ“Š TLCC Thresholdë³„ ì„±ëŠ¥ ë¶„ì„")
    print("="*60)
    
    # TLCC thresholdë³„ í‰ê·  ì„±ëŠ¥
    threshold_analysis = df.groupby('tlcc_threshold').agg({
        'best_f1': ['mean', 'std', 'max'],
        'epsilon_roc_auc': ['mean', 'std', 'max'],
        'epsilon_pr_auc': ['mean', 'std', 'max'],
        'epsilon_mcc': ['mean', 'std', 'max']
    }).round(4)
    
    print("\nğŸ“ˆ TLCC Thresholdë³„ í‰ê·  ì„±ëŠ¥:")
    print(threshold_analysis)
    
    # ìµœê³  ì„±ëŠ¥ TLCC threshold ì°¾ê¸°
    best_threshold = df.groupby('tlcc_threshold')['best_f1'].mean().idxmax()
    best_performance = df.groupby('tlcc_threshold')['best_f1'].mean().max()
    
    print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ TLCC Threshold: {best_threshold} (í‰ê·  F1: {best_performance:.4f})")

def analyze_by_epoch(df):
    """Epochë³„ ì„±ëŠ¥ ë¶„ì„"""
    print("\n" + "="*60)
    print("ğŸ“Š Epochë³„ ì„±ëŠ¥ ë¶„ì„")
    print("="*60)
    
    epoch_analysis = df.groupby('epoch').agg({
        'best_f1': ['mean', 'std', 'max'],
        'epsilon_roc_auc': ['mean', 'std', 'max'],
        'epsilon_pr_auc': ['mean', 'std', 'max'],
        'total_time': ['mean', 'std']
    }).round(4)
    
    print("\nğŸ“ˆ Epochë³„ ì„±ëŠ¥ ë° ì‹œê°„:")
    print(epoch_analysis)

def create_performance_visualizations(df, output_dir='analysis_plots'):
    """ì„±ëŠ¥ ì‹œê°í™” ìƒì„±"""
    Path(output_dir).mkdir(exist_ok=True)
    
    # 1. ë°ì´í„°ì…‹ë³„ ì„±ëŠ¥ ë¹„êµ
    plt.figure(figsize=(15, 12))
    
    # F1 Score ë¹„êµ
    plt.subplot(2, 3, 1)
    sns.boxplot(data=df, x='dataset', y='best_f1')
    plt.title('F1 Score by Dataset')
    plt.xticks(rotation=45)
    
    # ROC-AUC ë¹„êµ
    plt.subplot(2, 3, 2)
    sns.boxplot(data=df, x='dataset', y='epsilon_roc_auc')
    plt.title('ROC-AUC by Dataset')
    plt.xticks(rotation=45)
    
    # PR-AUC ë¹„êµ
    plt.subplot(2, 3, 3)
    sns.boxplot(data=df, x='dataset', y='epsilon_pr_auc')
    plt.title('PR-AUC by Dataset')
    plt.xticks(rotation=45)
    
    # TLCC Thresholdë³„ ì„±ëŠ¥
    plt.subplot(2, 3, 4)
    tlcc_performance = df.groupby('tlcc_threshold')['best_f1'].mean()
    plt.plot(tlcc_performance.index, tlcc_performance.values, 'o-')
    plt.xlabel('TLCC Threshold')
    plt.ylabel('Average F1 Score')
    plt.title('Performance vs TLCC Threshold')
    plt.grid(True)
    
    # Epochë³„ ì„±ëŠ¥
    plt.subplot(2, 3, 5)
    epoch_performance = df.groupby('epoch')['best_f1'].mean()
    plt.plot(epoch_performance.index, epoch_performance.values, 's-')
    plt.xlabel('Epochs')
    plt.ylabel('Average F1 Score')
    plt.title('Performance vs Epochs')
    plt.grid(True)
    
    # ì‹¤í–‰ ì‹œê°„ ë¶„ì„
    plt.subplot(2, 3, 6)
    sns.boxplot(data=df, x='epoch', y='total_time')
    plt.title('Training Time by Epochs')
    plt.ylabel('Time (seconds)')
    
    plt.tight_layout()
    plt.savefig(f'{output_dir}/comprehensive_performance_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

def create_heatmap_analysis(df, output_dir='analysis_plots'):
    """íˆíŠ¸ë§µ ë¶„ì„ ìƒì„±"""
    
    # ë°ì´í„°ì…‹ x TLCC threshold íˆíŠ¸ë§µ
    plt.figure(figsize=(12, 8))
    
    # F1 Score íˆíŠ¸ë§µ
    plt.subplot(2, 2, 1)
    heatmap_data = df.groupby(['dataset', 'tlcc_threshold'])['best_f1'].mean().unstack()
    sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='YlOrRd')
    plt.title('F1 Score: Dataset vs TLCC Threshold')
    
    # ROC-AUC íˆíŠ¸ë§µ
    plt.subplot(2, 2, 2)
    heatmap_data = df.groupby(['dataset', 'tlcc_threshold'])['epsilon_roc_auc'].mean().unstack()
    sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='YlOrRd')
    plt.title('ROC-AUC: Dataset vs TLCC Threshold')
    
    # PR-AUC íˆíŠ¸ë§µ
    plt.subplot(2, 2, 3)
    heatmap_data = df.groupby(['dataset', 'tlcc_threshold'])['epsilon_pr_auc'].mean().unstack()
    sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='YlOrRd')
    plt.title('PR-AUC: Dataset vs TLCC Threshold')
    
    # MCC íˆíŠ¸ë§µ
    plt.subplot(2, 2, 4)
    heatmap_data = df.groupby(['dataset', 'tlcc_threshold'])['epsilon_mcc'].mean().unstack()
    sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='YlOrRd')
    plt.title('MCC: Dataset vs TLCC Threshold')
    
    plt.tight_layout()
    plt.savefig(f'{output_dir}/heatmap_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

def find_best_configurations(df):
    """ìµœê³  ì„±ëŠ¥ ì„¤ì • ì°¾ê¸°"""
    print("\n" + "="*60)
    print("ğŸ† ìµœê³  ì„±ëŠ¥ ì„¤ì • ë¶„ì„")
    print("="*60)
    
    # ì „ì²´ ìµœê³  ì„±ëŠ¥
    best_overall = df.loc[df['best_f1'].idxmax()]
    print(f"\nğŸ¥‡ ì „ì²´ ìµœê³  ì„±ëŠ¥:")
    print(f"   Dataset: {best_overall['dataset']}")
    if best_overall['group'] != 'default':
        print(f"   Group: {best_overall['group']}")
    print(f"   Epoch: {best_overall['epoch']}")
    print(f"   TLCC Threshold: {best_overall['tlcc_threshold']}")
    print(f"   F1 Score: {best_overall['best_f1']:.4f}")
    print(f"   Method: {best_overall['best_method'].upper()}")
    
    # ë°ì´í„°ì…‹ë³„ ìµœê³  ì„±ëŠ¥
    print(f"\nğŸ“Š ë°ì´í„°ì…‹ë³„ ìµœê³  ì„±ëŠ¥:")
    for dataset in df['dataset'].unique():
        dataset_data = df[df['dataset'] == dataset]
        best_dataset = dataset_data.loc[dataset_data['best_f1'].idxmax()]
        
        print(f"\n   {dataset}:")
        if best_dataset['group'] != 'default':
            print(f"     Group: {best_dataset['group']}")
        print(f"     Epoch: {best_dataset['epoch']}")
        print(f"     TLCC Threshold: {best_dataset['tlcc_threshold']}")
        print(f"     F1 Score: {best_dataset['best_f1']:.4f}")
        print(f"     ROC-AUC: {best_dataset['epsilon_roc_auc']:.4f}")
        print(f"     PR-AUC: {best_dataset['epsilon_pr_auc']:.4f}")
        print(f"     MCC: {best_dataset['epsilon_mcc']:.4f}")

def generate_research_summary(df, output_file='research_summary.txt'):
    """ì—°êµ¬ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write("ì´ìƒ íƒì§€ í¬ê´„ì  ì‹¤í—˜ ê²°ê³¼ ìš”ì•½ ë¦¬í¬íŠ¸\n")
        f.write("="*80 + "\n\n")
        
        # ì‹¤í—˜ ê°œìš”
        f.write("ğŸ“‹ ì‹¤í—˜ ê°œìš”\n")
        f.write("-" * 40 + "\n")
        f.write(f"ì´ ì‹¤í—˜ ìˆ˜: {len(df)}\n")
        f.write(f"ë°ì´í„°ì…‹: {', '.join(df['dataset'].unique())}\n")
        f.write(f"ì—í­ ë²”ìœ„: {df['epoch'].min()} - {df['epoch'].max()}\n")
        f.write(f"TLCC Threshold ë²”ìœ„: {df['tlcc_threshold'].min()} - {df['tlcc_threshold'].max()}\n\n")
        
        # ì£¼ìš” ë°œê²¬ì‚¬í•­
        f.write("ğŸ” ì£¼ìš” ë°œê²¬ì‚¬í•­\n")
        f.write("-" * 40 + "\n")
        
        # ìµœê³  ì„±ëŠ¥ TLCC threshold
        best_tlcc = df.groupby('tlcc_threshold')['best_f1'].mean().idxmax()
        f.write(f"1. ìµœì  TLCC Threshold: {best_tlcc}\n")
        
        # ë°ì´í„°ì…‹ë³„ í‰ê·  ì„±ëŠ¥
        f.write("2. ë°ì´í„°ì…‹ë³„ í‰ê·  F1 ì„±ëŠ¥:\n")
        for dataset in df['dataset'].unique():
            avg_f1 = df[df['dataset'] == dataset]['best_f1'].mean()
            f.write(f"   - {dataset}: {avg_f1:.4f}\n")
        
        # ì—í­ íš¨ê³¼
        epoch_corr = df['epoch'].corr(df['best_f1'])
        f.write(f"3. ì—í­ê³¼ ì„±ëŠ¥ ìƒê´€ê´€ê³„: {epoch_corr:.4f}\n")
        
        f.write("\n" + "="*80 + "\n")
    
    print(f"ğŸ“„ ì—°êµ¬ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±: {output_file}")

def main():
    """ë©”ì¸ ë¶„ì„ í•¨ìˆ˜"""
    print("ğŸ“Š í¬ê´„ì  ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ ì‹œì‘")
    
    # ìµœì‹  ê²°ê³¼ íŒŒì¼ ì°¾ê¸° ë˜ëŠ” íŒŒì¼ëª… ì§€ì •
    import glob
    result_files = glob.glob("comprehensive_experiment_results_*.csv")
    if result_files:
        latest_file = max(result_files, key=lambda x: Path(x).stat().st_mtime)
        print(f"ğŸ“ ë¶„ì„ ëŒ€ìƒ íŒŒì¼: {latest_file}")
    else:
        print("âŒ ì‹¤í—˜ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë°ì´í„° ë¡œë“œ
    df = load_experiment_results(latest_file)
    if df is None:
        return
    
    # ë¶„ì„ ì‹¤í–‰
    analyze_by_dataset(df)
    analyze_by_tlcc_threshold(df)
    analyze_by_epoch(df)
    find_best_configurations(df)
    
    # ì‹œê°í™” ìƒì„±
    create_performance_visualizations(df)
    create_heatmap_analysis(df)
    
    # ì—°êµ¬ ìš”ì•½ ìƒì„±
    generate_research_summary(df)
    
    print("\nğŸ‰ ë¶„ì„ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
