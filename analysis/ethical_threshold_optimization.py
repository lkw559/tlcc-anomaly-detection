#!/usr/bin/env python3
"""
ì—°êµ¬ìœ¤ë¦¬ì— ë§ëŠ” ì„ê³„ê°’ ìµœì í™” ë°©ë²•
Cross-validationì„ í†µí•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
"""

import numpy as np
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import f1_score
import warnings
warnings.filterwarnings('ignore')

def ethical_threshold_optimization(train_scores, train_labels=None, method='cv'):
    """
    ì—°êµ¬ìœ¤ë¦¬ì— ë§ëŠ” ì„ê³„ê°’ ìµœì í™”
    
    Args:
        train_scores: í›ˆë ¨ ë°ì´í„°ì˜ anomaly scores
        train_labels: í›ˆë ¨ ë°ì´í„°ì˜ labels (ìˆë‹¤ë©´)
        method: 'cv' (cross-validation) ë˜ëŠ” 'heuristic'
    
    Returns:
        ìµœì  percentile ê°’
    """
    
    if method == 'cv' and train_labels is not None:
        return _cross_validation_optimization(train_scores, train_labels)
    else:
        return _heuristic_optimization(train_scores)

def _cross_validation_optimization(train_scores, train_labels):
    """
    Cross-validationì„ í†µí•œ ìœ¤ë¦¬ì  ìµœì í™”
    """
    print("ğŸ“Š Cross-Validation ê¸°ë°˜ ì„ê³„ê°’ ìµœì í™” ìˆ˜í–‰")
    
    # Time series split (ì‹œê³„ì—´ ë°ì´í„° íŠ¹ì„± ê³ ë ¤)
    tscv = TimeSeriesSplit(n_splits=5)
    
    # í…ŒìŠ¤íŠ¸í•  percentile í›„ë³´ë“¤ (ì‚¬ì „ ì •ì˜)
    percentile_candidates = [90, 92, 94, 95, 96, 97, 98, 99]
    
    best_percentile = 95  # ê¸°ë³¸ê°’
    best_cv_score = 0
    
    print("Percentile | CV F1 Score")
    print("-" * 25)
    
    for percentile in percentile_candidates:
        cv_scores = []
        
        for train_idx, val_idx in tscv.split(train_scores):
            # Train/Validation split
            train_fold = train_scores[train_idx]
            val_scores = train_scores[val_idx]
            val_labels = train_labels[val_idx]
            
            # ì„ê³„ê°’ ê³„ì‚° (train_foldë§Œ ì‚¬ìš©)
            threshold = np.percentile(train_fold, percentile)
            
            # Validationì—ì„œ í‰ê°€
            pred = (val_scores > threshold).astype(int)
            f1 = f1_score(val_labels, pred, zero_division=0)
            cv_scores.append(f1)
        
        mean_cv_score = np.mean(cv_scores)
        print(f"{percentile:8d}   | {mean_cv_score:.4f}")
        
        if mean_cv_score > best_cv_score:
            best_cv_score = mean_cv_score
            best_percentile = percentile
    
    print(f"\nğŸ† Cross-validation ìµœì  percentile: {best_percentile}")
    print(f"ğŸ¯ Cross-validation F1 score: {best_cv_score:.4f}")
    
    return best_percentile

def _heuristic_optimization(train_scores):
    """
    íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ìµœì í™” (ë¼ë²¨ì´ ì—†ì„ ë•Œ)
    """
    print("ğŸ” Heuristic ê¸°ë°˜ ì„ê³„ê°’ ìµœì í™” ìˆ˜í–‰")
    
    # í†µê³„ì  íŠ¹ì„± ë¶„ì„
    stats = {
        'mean': np.mean(train_scores),
        'std': np.std(train_scores),
        'median': np.median(train_scores),
        'q90': np.percentile(train_scores, 90),
        'q95': np.percentile(train_scores, 95),
        'q99': np.percentile(train_scores, 99),
    }
    
    print(f"Score í†µê³„:")
    for k, v in stats.items():
        print(f"  {k}: {v:.6f}")
    
    # íœ´ë¦¬ìŠ¤í‹± ê·œì¹™ë“¤
    rules = {
        'conservative': 99,  # ë³´ìˆ˜ì : 99th percentile
        'balanced': 95,      # ê· í˜•ì : 95th percentile  
        'sensitive': 90,     # ë¯¼ê°í•œ: 90th percentile
    }
    
    # ë°ì´í„° ë¶„í¬ì— ë”°ë¥¸ ì„ íƒ
    coefficient_of_variation = stats['std'] / stats['mean']
    
    if coefficient_of_variation < 0.3:
        # ë¶„ì‚°ì´ ì‘ìœ¼ë©´ ë” ë¯¼ê°í•˜ê²Œ
        recommended = 'sensitive'
    elif coefficient_of_variation > 0.8:
        # ë¶„ì‚°ì´ í¬ë©´ ë” ë³´ìˆ˜ì ìœ¼ë¡œ
        recommended = 'conservative'
    else:
        # ì¤‘ê°„ ì •ë„ë©´ ê· í˜•ì ìœ¼ë¡œ
        recommended = 'balanced'
    
    selected_percentile = rules[recommended]
    
    print(f"\nğŸ“Š ë¶„í¬ íŠ¹ì„±:")
    print(f"  Coefficient of Variation: {coefficient_of_variation:.3f}")
    print(f"  ê¶Œì¥ ì „ëµ: {recommended}")
    print(f"  ì„ íƒëœ percentile: {selected_percentile}")
    
    return selected_percentile

def validate_threshold_method(train_scores, test_scores, test_labels, percentile):
    """
    ì„ íƒëœ ì„ê³„ê°’ ë°©ë²•ì˜ ì„±ëŠ¥ ê²€ì¦
    """
    threshold = np.percentile(train_scores, percentile)
    pred = (test_scores > threshold).astype(int)
    
    if test_labels is not None:
        f1 = f1_score(test_labels, pred, zero_division=0)
        print(f"\nâœ… ìµœì¢… í…ŒìŠ¤íŠ¸ ì„±ëŠ¥:")
        print(f"  Percentile: {percentile}")
        print(f"  Threshold: {threshold:.6f}")
        print(f"  Test F1 Score: {f1:.4f}")
        return f1
    else:
        print(f"\nğŸ“‹ ì„ íƒëœ ì„ê³„ê°’:")
        print(f"  Percentile: {percentile}")
        print(f"  Threshold: {threshold:.6f}")
        return threshold

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°
    np.random.seed(42)
    n_samples = 10000
    
    # ì •ìƒ ë°ì´í„° (ë‚®ì€ ì ìˆ˜)
    normal_scores = np.random.exponential(0.1, int(n_samples * 0.95))
    normal_labels = np.zeros(len(normal_scores))
    
    # ì´ìƒ ë°ì´í„° (ë†’ì€ ì ìˆ˜)
    anomaly_scores = np.random.exponential(0.3, int(n_samples * 0.05)) + 0.2
    anomaly_labels = np.ones(len(anomaly_scores))
    
    # ë°ì´í„° í•©ì¹˜ê¸°
    all_scores = np.concatenate([normal_scores, anomaly_scores])
    all_labels = np.concatenate([normal_labels, anomaly_labels])
    
    # ì‹œê°„ìˆœìœ¼ë¡œ ì„ê¸° (í˜„ì‹¤ì ìœ¼ë¡œ)
    idx = np.random.permutation(len(all_scores))
    all_scores = all_scores[idx]
    all_labels = all_labels[idx]
    
    # Train/Test split (ì‹œê³„ì—´ì´ë¯€ë¡œ ì‹œê°„ìˆœ)
    split_point = int(len(all_scores) * 0.7)
    train_scores = all_scores[:split_point]
    train_labels = all_labels[:split_point]
    test_scores = all_scores[split_point:]
    test_labels = all_labels[split_point:]
    
    print("=" * 60)
    print("ì—°êµ¬ìœ¤ë¦¬ì— ë§ëŠ” ì„ê³„ê°’ ìµœì í™” ì˜ˆì‹œ")
    print("=" * 60)
    
    # ìœ¤ë¦¬ì  ìµœì í™” ìˆ˜í–‰
    optimal_percentile = ethical_threshold_optimization(
        train_scores, train_labels, method='cv'
    )
    
    # ìµœì¢… ê²€ì¦
    validate_threshold_method(
        train_scores, test_scores, test_labels, optimal_percentile
    )
